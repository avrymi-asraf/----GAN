{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avrymi-asraf/Garden-of-GAN/blob/main/2-More-Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-wCKej-0yAw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import ceil\n",
        "def train_model(dis, gen, epoches,batch_size, dataset,device,loss_f,optim_dis,optim_gen):\n",
        "    '''Trains a generative adversarial network (GAN) model.\n",
        "\n",
        "    Args:\n",
        "        dis (torch.nn.Module): The discriminator model.\n",
        "        gen (torch.nn.Module): The generator model.\n",
        "        epoches (int): Number of training epochs.\n",
        "        batch_size (int): Size of the batches used during training.\n",
        "        dataset (torch.utils.data.Dataset): The dataset for training.\n",
        "        device (torch.device): The device to run the models on (e.g., 'cpu' or 'cuda').\n",
        "        loss_f (callable): The loss function used for training.\n",
        "        optim_dis (torch.optim.Optimizer): Optimizer for the discriminator.\n",
        "        optim_gen (torch.optim.Optimizer): Optimizer for the generator.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the training progress, with columns:\n",
        "                      \"epoch\", \"batch\", \"loss_gen\", and \"loss_dis\".\n",
        "    '''\n",
        "    run_ind = 0\n",
        "    run_data = pd.DataFrame(columns=[\"epoch\",\"batch\",\"loss_gen\",\"loss_dis\"],index=range(ceil(len(dataset)/batch_size)*epoches))\n",
        "    data_loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
        "    for i in range(epoches):\n",
        "        start_time = time.time()\n",
        "        for j,(x,y) in enumerate(data_loader):\n",
        "            x = x.to(device)\n",
        "            y_hat = dis(x).flatten()\n",
        "            loss_dis_1 = loss_f(y_hat,torch.ones(len(x),device=device))\n",
        "\n",
        "            noise = torch.randn(len(x),100).to(device)\n",
        "            y_hat = dis(gen(noise)).flatten()\n",
        "            loss_dis_2 = loss_f(y_hat,torch.zeros(len(x),device=device))\n",
        "            loss_dis = loss_dis_1 + loss_dis_2/2\n",
        "\n",
        "            optim_dis.zero_grad()\n",
        "            loss_dis.backward()\n",
        "            optim_dis.step()\n",
        "\n",
        "            noise = torch.randn(len(x),100).to(device)\n",
        "            y_hat = dis(gen(noise)).flatten()\n",
        "            loss_gen = loss_f(y_hat,torch.ones(len(x),device=device))\n",
        "            optim_gen.zero_grad()\n",
        "            loss_gen.backward()\n",
        "            optim_gen.step()\n",
        "\n",
        "            run_data.loc[run_ind] = [i,j,loss_gen.item(),loss_dis.item()]\n",
        "            run_ind+=1\n",
        "        clear_output(wait=True)\n",
        "        px.line(run_data,x=run_data.index,y=[\"loss_gen\",\"loss_dis\"]).show()\n",
        "        exapmle = gen(torch.randn(5,100).to(device)).detach().cpu().permute(0,2,3,1)\n",
        "        px.imshow(exapmle,facet_col=0,facet_col_wrap=5).show()\n",
        "        print(f'run time: {time.time()-start_time:03f}')\n",
        "    return run_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wCwedxdyGpYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clifar10 = datasets.CIFAR10(root=\"data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(0,1)]))"
      ],
      "metadata": {
        "id": "1btKfDst1AjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discrimnator_32(nn.Module):\n",
        "    def __init__(self,im_dim=(3,32,32)):\n",
        "        super().__init__()\n",
        "        self.im_dim = im_dim\n",
        "        self.conv1 = nn.Conv2d(in_channels=self.im_dim[0],out_channels=64,kernel_size=4,stride=2,padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1)\n",
        "        self.lin = nn.Linear(in_features=256*4*4,out_features=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1,256*4*4)\n",
        "        x = self.lin(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "class Generator_32(nn.Module):\n",
        "    def __init__(self,letant_dim=100):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(in_features=letant_dim,out_features=256*4*4)\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=4,stride=2,padding=1,output_padding=0)\n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=4,stride=2,padding=1,output_padding=0)\n",
        "        self.conv3 = nn.ConvTranspose2d(in_channels=64,out_channels=3,kernel_size=4,stride=2,padding=1,output_padding=0)\n",
        "        self.tanh = nn.Tanh()\n",
        "    def forward(self,x):\n",
        "        x = self.lin(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1,256,4,4)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Z70HhggE1TS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dis = Discrimnator()\n",
        "# dis(clifar10[0][0])"
      ],
      "metadata": {
        "id": "0E1qr9Me2G7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# px.imshow(gen(torch.randn(1,100)).detach().squeeze().permute(1,2,0))"
      ],
      "metadata": {
        "id": "Anl3kx3j3Vxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator  = Generator().to(device)\n",
        "discriminator = Discrimnator().to(device)\n",
        "optim_gen = torch.optim.Adam(generator.parameters(),lr=0.0002)\n",
        "optim_dis = torch.optim.Adam(discriminator.parameters(),lr=0.0002)\n",
        "loss_f = nn.BCELoss()"
      ],
      "metadata": {
        "id": "pLqtT2Zs3X-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epocs = 20\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "Mqf_u1PX7POY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = datasets.MNIST(root=\"data\", train=True, download=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize(0,1),transforms.Resize((32,32)),transforms.Lambda(lambda x: x.repeat(3,1,1))]))\n",
        "# px.imshow(mnist[0][0].permute(1,2,0))\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "dX9g_XxN8mfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator  = Generator().to(device)\n",
        "discriminator = Discrimnator().to(device)\n",
        "optim_gen = torch.optim.Adam(generator.parameters(),lr=0.0002)\n",
        "optim_dis = torch.optim.Adam(discriminator.parameters(),lr=0.0002)\n",
        "loss_f = nn.BCELoss()"
      ],
      "metadata": {
        "id": "yecV-2tmB3Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epocs = 20\n",
        "batch_size = 128"
      ],
      "metadata": {
        "id": "cfN7fq27B3Ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(discriminator,generator,epocs,batch_size,mnist,device,loss_f,optim_dis,optim_gen)"
      ],
      "metadata": {
        "id": "5IiIN3yaS2iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/avrymi-asraf/Garden-of-GAN/raw/main/mini_celebA.zip -O mini_celebA.zip\n",
        "!unzip mini_celebA.zip\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Zt7huKKT4zH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/mini_celebA\n",
        "!mkdir data/mini_celebA/class_0\n",
        "!mv mini_selebA* data/mini_celebA/class_0"
      ],
      "metadata": {
        "id": "p5M8fZwcbK-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "     transforms.CenterCrop((178,178)),\n",
        "    transforms.Resize((128,128)),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "id": "Lc3bhaZdCtPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discrimnator_128(nn.Module):\n",
        "    def __init__(self,im_dim=(3,128,128)):\n",
        "        super().__init__()\n",
        "        self.im_dim = im_dim\n",
        "        self.conv1 = nn.Conv2d(in_channels=self.im_dim[0],out_channels=64,kernel_size=4,stride=2,padding=1)\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=4,stride=2,padding=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=4,stride=2,padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=4,stride=4,padding=1)\n",
        "        self.lin = nn.Linear(in_features=256*4*4,out_features=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1,256*4*4)\n",
        "        x = self.lin(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "class Generator_128(nn.Module):\n",
        "    def __init__(self,letant_dim=100):\n",
        "        super().__init__()\n",
        "        self.lin = nn.Linear(in_features=letant_dim,out_features=256*4*4)\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.conv1 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=4,stride=2,padding=1,output_padding=0)\n",
        "        self.conv2 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=4,stride=4,padding=1,output_padding=2)\n",
        "        self.conv3 = nn.ConvTranspose2d(in_channels=64,out_channels=3,kernel_size=4,stride=4,padding=1,output_padding=2)\n",
        "        self.tanh = nn.Tanh()\n",
        "    def forward(self,x):\n",
        "        x = self.lin(x)\n",
        "        x = self.relu(x)\n",
        "        x = x.view(-1,256,4,4)\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "F162fYWoim5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(Discrimnator()(dataset[0][0]).item())\n",
        "# px.imshow(Generator()(torch.randn(1,100)).detach().squeeze().permute(1,2,0))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2uReZjxSEXem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataset = datasets.ImageFolder(root='data/mini_celebA', transform=transform)\n",
        "gen = Generator().to(device)\n",
        "dis = Discrimnator().to(device)"
      ],
      "metadata": {
        "id": "KzWQzVk0Hs0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoches = 100\n",
        "batch_size = 64\n",
        "\n",
        "optim_gen = torch.optim.Adam(gen.parameters(),lr=0.0002)\n",
        "optim_dis = torch.optim.Adam(dis.parameters(),lr=0.0002)\n",
        "loss_f = nn.BCELoss()"
      ],
      "metadata": {
        "id": "drX945g9HznB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_data = train_model(dis,gen,epoches,batch_size,dataset,device,loss_f,optim_dis,optim_gen)"
      ],
      "metadata": {
        "id": "KjKgA2VxIp6D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
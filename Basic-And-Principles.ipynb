{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avrymi-asraf/Garden-of-GAN/blob/main/Basic-And-Principles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6B4zf9Ptk36"
      },
      "source": [
        "# Basic and Principle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and Import"
      ],
      "metadata": {
        "id": "NpgcMhget3UH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6Ygl-dhvvfDp"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchvision plotly tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QYYopqePvwtD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.utils.data.dataloader as dataloader\n",
        "from torchvision import datasets, transforms\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import plotly.figure_factory as ff"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Callable"
      ],
      "metadata": {
        "id": "p8HW3Nz_78-a"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Model"
      ],
      "metadata": {
        "id": "6ENLba0wvSpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the generator network\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim, output_dim):\n",
        "    super(Generator, self).__init__()\n",
        "    # MLP with dense layers and activations\n",
        "    self.fc1 = nn.Linear(noise_dim, 128)\n",
        "    self.relu = nn.LeakyReLU(0.2)\n",
        "    self.fc2 = nn.Linear(128, output_dim)\n",
        "\n",
        "  def forward(self, z):\n",
        "    x = self.fc1(z)\n",
        "    x = self.relu(x)\n",
        "    return self.fc2(x)\n",
        "\n",
        "# Define the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super(Discriminator, self).__init__()\n",
        "    # MLP with dense layers and activations\n",
        "    self.fc1 = nn.Linear(input_dim, 128)\n",
        "    self.relu = nn.LeakyReLU(0.2)\n",
        "    self.fc2 = nn.Linear(128, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.relu(x)\n",
        "    return self.sigmoid(self.fc2(x))\n"
      ],
      "metadata": {
        "id": "jrUnivAx68TR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussians(batch_size:int=64,mean:Optional[torch.Tensor]=None,var:Optional[torch.Tensor]=None)->Callable[[],torch.Tensor]:\n",
        "    mean = var if mean else torch.rand(1)*torch.randint(-5,5,[1])\n",
        "    var = var if var else torch.rand(1)*torch.randint(0,10,[1])\n",
        "    return lambda: (torch.randn(batch_size)*var + mean).unsqueeze(1)\n",
        "# ff.create_distplot([gaussians()().tolist(),gaussians()().tolist()],['1','2'])\n"
      ],
      "metadata": {
        "id": "L10w3QGw7FY4"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "batch_size = 64\n",
        "noise_dim = 100\n",
        "output_dim = 1  # Assuming 4-dimensional distribution\n",
        "generator = Generator(noise_dim, output_dim).to(device)\n",
        "discriminator = Discriminator(output_dim).to(device)\n",
        "sampler = gaussians(batch_size)\n",
        "# Define loss functions and optimizers\n",
        "loss_function_D = nn.BCELoss()\n",
        "loss_function_G = nn.BCELoss()\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=0.0002)\n"
      ],
      "metadata": {
        "id": "j2SUWspa7CMg"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(10000):\n",
        "  # Sample real data and noise\n",
        "  real_data = sampler().to(device)\n",
        "  noise = torch.randn(batch_size, noise_dim).to(device)\n",
        "\n",
        "  # Train discriminator\n",
        "  real_labels = torch.ones((batch_size,1)).to(device)\n",
        "  fake_labels = torch.zeros((batch_size,1)).to(device)\n",
        "\n",
        "  # Real data pass\n",
        "  discriminator_output = discriminator(real_data.float())\n",
        "  D_real_loss = loss_function_D(discriminator_output, real_labels)\n",
        "\n",
        "  # Fake data pass\n",
        "  fake_data = generator(noise)\n",
        "  discriminator_output = discriminator(fake_data)\n",
        "  D_fake_loss = loss_function_D(discriminator_output, fake_labels)\n",
        "\n",
        "  # Total discriminator loss\n",
        "  D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "  # Reset and update discriminator\n",
        "  optimizer_D.zero_grad()\n",
        "  D_loss.backward()\n",
        "  optimizer_D.step()\n",
        "\n",
        "  # Train generator\n",
        "  fake_labels = torch.ones((batch_size,1)).to(device)\n",
        "  generator_output = generator(noise)\n",
        "  G_loss = loss_function_G(discriminator(generator_output), fake_labels)\n",
        "\n",
        "  # Reset and update generator\n",
        "  optimizer_G.zero_grad()\n",
        "  G_loss.backward()\n",
        "  optimizer_G.step()\n",
        "\n",
        "  # Print losses and visualize progress (optional)\n",
        "  if epoch % 500 == 0:\n",
        "    print(\"Epoch:\", epoch, \"D_loss:\", D_loss.item(), \"G_loss:\", G_loss.item())\n",
        "    clear_output(wait=True)\n",
        "    ff.create_distplot([sampler().view((batch_size)).tolist(),generator_output.view((batch_size)).cpu().detach().tolist()],[\"rael\",\"generator\"]).show()\n"
      ],
      "metadata": {
        "id": "HWCXPdo33cHL",
        "outputId": "d32e8cf9-8f08-42b4-a6bb-cb11cdd5dc52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"4f0add28-fd8b-42ed-a70e-663b79da68fc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4f0add28-fd8b-42ed-a70e-663b79da68fc\")) {                    Plotly.newPlot(                        \"4f0add28-fd8b-42ed-a70e-663b79da68fc\",                        [{\"autobinx\":false,\"histnorm\":\"probability density\",\"legendgroup\":\"rael\",\"marker\":{\"color\":\"rgb(31, 119, 180)\"},\"name\":\"rael\",\"opacity\":0.7,\"x\":[0.31926533579826355,0.1970769464969635,0.0918283462524414,0.04214535653591156,0.38781440258026123,0.45149990916252136,0.6570965647697449,-0.16994699835777283,0.05970039963722229,0.1312589943408966,0.0894184485077858,0.48843494057655334,-0.11010244488716125,0.09856948256492615,0.0716269463300705,0.3288358747959137,-0.08256645500659943,-0.4083579182624817,0.4074728190898895,0.2674974799156189,-0.3110252320766449,0.2609313130378723,0.5058010816574097,0.3545064330101013,-0.20491209626197815,0.08470205962657928,-0.019575923681259155,0.08613456785678864,0.08869387209415436,-0.030085280537605286,0.17265862226486206,-0.18869686126708984,0.07879428565502167,0.4340452253818512,-0.07059131562709808,-0.0018469244241714478,0.05014371871948242,0.5858950614929199,0.15157881379127502,0.16910795867443085,-0.1486910581588745,0.07999926060438156,-0.10819773375988007,-0.22044184803962708,0.3097939193248749,0.0016308650374412537,0.10859505832195282,0.4524754583835602,0.4831377863883972,-0.5370943546295166,0.3384043872356415,0.09997327625751495,0.15340037643909454,0.3289087116718292,1.0907001495361328,0.1788521707057953,0.3813215494155884,0.2748507261276245,0.5244182348251343,0.5940709710121155,-0.21061784029006958,-0.13652488589286804,0.3958180248737335,-0.4469004273414612],\"xaxis\":\"x\",\"xbins\":{\"end\":1.0907001495361328,\"size\":1.0,\"start\":-0.5370943546295166},\"yaxis\":\"y\",\"type\":\"histogram\"},{\"autobinx\":false,\"histnorm\":\"probability density\",\"legendgroup\":\"generator\",\"marker\":{\"color\":\"rgb(255, 127, 14)\"},\"name\":\"generator\",\"opacity\":0.7,\"x\":[0.3750627636909485,0.3234071135520935,0.3011435568332672,0.1783347725868225,0.22536218166351318,0.015400712378323078,0.22065138816833496,0.25865939259529114,0.2853989899158478,0.050407830625772476,0.2753312289714813,0.13464973866939545,0.21381717920303345,0.18111157417297363,0.23170766234397888,0.4279977083206177,0.13508360087871552,0.3777902126312256,0.57640141248703,0.41349196434020996,0.2106437087059021,0.3964504599571228,0.2998558282852173,0.2847467362880707,0.15398472547531128,0.31465256214141846,0.14590299129486084,0.38340049982070923,0.4614834189414978,0.5076261758804321,0.23645830154418945,0.2720438838005066,0.312058687210083,0.2172023057937622,0.3174465596675873,0.30015963315963745,0.11591347306966782,0.2926647961139679,0.2682541012763977,0.2602398991584778,0.25645798444747925,0.29681554436683655,0.26281991600990295,0.31969764828681946,0.22756828367710114,0.3957976698875427,0.2629767954349518,0.07052788138389587,0.35178208351135254,0.28167787194252014,0.5017540454864502,0.2157885581254959,0.22387313842773438,0.292562872171402,0.3120690882205963,0.2784305214881897,0.261816143989563,0.4083458185195923,0.19985023140907288,0.42038148641586304,0.18163830041885376,0.2796711325645447,0.31163734197616577,0.24376320838928223],\"xaxis\":\"x\",\"xbins\":{\"end\":0.57640141248703,\"size\":1.0,\"start\":0.015400712378323078},\"yaxis\":\"y\",\"type\":\"histogram\"},{\"legendgroup\":\"rael\",\"marker\":{\"color\":\"rgb(31, 119, 180)\"},\"mode\":\"lines\",\"name\":\"rael\",\"showlegend\":false,\"x\":[-0.5370943546295166,-0.5338387656211853,-0.530583176612854,-0.5273275876045227,-0.5240719985961914,-0.5208164095878601,-0.5175608205795288,-0.5143052315711976,-0.5110496425628662,-0.5077940535545349,-0.5045384645462037,-0.5012828755378723,-0.49802728652954104,-0.4947716975212097,-0.4915161085128784,-0.48826051950454713,-0.48500493049621585,-0.4817493414878845,-0.4784937524795532,-0.47523816347122194,-0.4719825744628906,-0.4687269854545593,-0.46547139644622804,-0.4622158074378967,-0.4589602184295654,-0.45570462942123413,-0.45244904041290285,-0.44919345140457156,-0.4459378623962402,-0.44268227338790894,-0.43942668437957766,-0.4361710953712463,-0.43291550636291504,-0.42965991735458375,-0.4264043283462524,-0.42314873933792113,-0.41989315032958985,-0.41663756132125856,-0.4133819723129272,-0.41012638330459594,-0.40687079429626466,-0.4036152052879334,-0.40035961627960204,-0.39710402727127075,-0.39384843826293947,-0.39059284925460813,-0.38733726024627685,-0.38408167123794557,-0.3808260822296142,-0.377570493221283,-0.37431490421295166,-0.3710593152046203,-0.3678037261962891,-0.36454813718795775,-0.36129254817962647,-0.3580369591712952,-0.35478137016296385,-0.35152578115463257,-0.3482701921463013,-0.34501460313796994,-0.34175901412963866,-0.3385034251213074,-0.33524783611297604,-0.3319922471046448,-0.32873665809631347,-0.3254810690879822,-0.3222254800796509,-0.31896989107131957,-0.3157143020629883,-0.312458713054657,-0.30920312404632566,-0.3059475350379944,-0.3026919460296631,-0.29943635702133176,-0.29618076801300053,-0.2929251790046692,-0.28966958999633785,-0.28641400098800657,-0.2831584119796753,-0.279902822971344,-0.2766472339630127,-0.2733916449546814,-0.2701360559463501,-0.2668804669380188,-0.2636248779296875,-0.2603692889213562,-0.2571136999130249,-0.2538581109046936,-0.2506025218963623,-0.247346932888031,-0.24409134387969972,-0.24083575487136843,-0.2375801658630371,-0.2343245768547058,-0.23106898784637453,-0.2278133988380432,-0.2245578098297119,-0.22130222082138062,-0.21804663181304934,-0.214791042804718,-0.21153545379638672,-0.20827986478805544,-0.2050242757797241,-0.2017686867713928,-0.19851309776306153,-0.19525750875473025,-0.1920019197463989,-0.18874633073806762,-0.18549074172973634,-0.182235152721405,-0.17897956371307372,-0.17572397470474244,-0.17246838569641115,-0.16921279668807981,-0.16595720767974853,-0.16270161867141725,-0.15944602966308596,-0.15619044065475463,-0.15293485164642334,-0.14967926263809206,-0.14642367362976072,-0.14316808462142944,-0.13991249561309815,-0.13665690660476687,-0.13340131759643553,-0.13014572858810425,-0.12689013957977296,-0.12363455057144163,-0.12037896156311034,-0.11712337255477906,-0.11386778354644778,-0.11061219453811644,-0.10735660552978515,-0.10410101652145387,-0.10084542751312253,-0.09758983850479125,-0.09433424949645997,-0.09107866048812868,-0.08782307147979734,-0.08456748247146606,-0.08131189346313478,-0.0780563044548035,-0.07480071544647215,-0.07154512643814087,-0.06828953742980959,-0.06503394842147825,-0.061778359413146966,-0.05852277040481568,-0.0552671813964844,-0.05201159238815306,-0.04875600337982178,-0.045500414371490494,-0.042244825363159155,-0.03898923635482787,-0.03573364734649653,-0.032478058338165305,-0.029222469329833967,-0.02596688032150274,-0.0227112913131714,-0.01945570230484006,-0.016200113296508833,-0.012944524288177495,-0.009688935279846156,-0.006433346271514928,-0.0031777572631835893,7.783174514774949e-05,0.0033334207534789773,0.006589009761810316,0.009844598770141655,0.013100187778472883,0.01635577678680422,0.01961136579513545,0.022866954803466788,0.026122543811798127,0.029378132820129355,0.03263372182846069,0.03588931083679203,0.03914489984512326,0.0424004888534546,0.04565607786178594,0.048911666870117165,0.052167255878448504,0.05542284488677973,0.05867843389511107,0.06193402290344241,0.06518961191177364,0.06844520092010498,0.07170078992843631,0.07495637893676754,0.07821196794509888,0.08146755695343022,0.08472314596176145,0.08797873497009279,0.09123432397842413,0.09448991298675535,0.09774550199508669,0.10100109100341792,0.10425668001174926,0.1075122690200806,0.11076785802841183,0.11402344703674316,0.1172790360450745,0.12053462505340573,0.12379021406173707,0.1270458030700684,0.13030139207839964,0.13355698108673097,0.1368125700950622,0.14006815910339354,0.14332374811172488,0.1465793371200561,0.14983492612838745,0.15309051513671879,0.15634610414505,0.15960169315338135,0.1628572821617127,0.16611287117004392,0.16936846017837526,0.1726240491867066,0.17587963819503782,0.17913522720336916,0.1823908162117004,0.18564640522003173,0.18890199422836307,0.1921575832366943,0.19541317224502563,0.19866876125335697,0.2019243502616882,0.20517993927001954,0.20843552827835088,0.2116911172866821,0.21494670629501345,0.21820229530334467,0.221457884311676,0.22471347332000735,0.22796906232833858,0.23122465133666992,0.23448024034500126,0.23773582935333248,0.24099141836166382,0.24424700736999516,0.2475025963783264,0.25075818538665773,0.25401377439498907,0.2572693634033203,0.26052495241165163,0.26378054141998286,0.2670361304283142,0.27029171943664554,0.27354730844497677,0.2768028974533081,0.28005848646163944,0.28331407546997067,0.286569664478302,0.28982525348663335,0.2930808424949646,0.2963364315032959,0.29959202051162714,0.3028476095199585,0.3061031985282898,0.30935878753662105,0.3126143765449524,0.3158699655532837,0.31912555456161495,0.3223811435699463,0.32563673257827763,0.32889232158660886,0.3321479105949402,0.33540349960327154,0.33865908861160277,0.3419146776199341,0.34517026662826533,0.34842585563659667,0.351681444644928,0.35493703365325924,0.3581926226615906,0.3614482116699219,0.36470380067825314,0.3679593896865845,0.3712149786949158,0.37447056770324705,0.3777261567115784,0.3809817457199096,0.38423733472824095,0.3874929237365723,0.3907485127449035,0.39400410175323486,0.3972596907615662,0.4005152797698974,0.40377086877822876,0.4070264577865601,0.41028204679489133,0.41353763580322267,0.416793224811554,0.42004881381988524,0.4233044028282166,0.4265599918365478,0.42981558084487914,0.4330711698532105,0.4363267588615417,0.43958234786987305,0.4428379368782044,0.4460935258865356,0.44934911489486695,0.4526047039031983,0.4558602929115295,0.45911588191986086,0.4623714709281921,0.46562705993652354,0.46888264894485476,0.472138237953186,0.47539382696151744,0.47864941596984867,0.4819050049781799,0.4851605939865111,0.4884161829948426,0.4916717720031738,0.49492736101150503,0.4981829500198365,0.5014385390281677,0.5046941280364989,0.5079497170448304,0.5112053060531616,0.5144608950614928,0.5177164840698243,0.5209720730781555,0.5242276620864867,0.5274832510948182,0.5307388401031494,0.5339944291114807,0.5372500181198121,0.5405056071281433,0.5437611961364746,0.547016785144806,0.5502723741531372,0.5535279631614685,0.5567835521697999,0.5600391411781311,0.5632947301864624,0.5665503191947936,0.569805908203125,0.5730614972114563,0.5763170862197875,0.579572675228119,0.5828282642364502,0.5860838532447814,0.5893394422531129,0.5925950312614441,0.5958506202697753,0.5991062092781068,0.602361798286438,0.6056173872947692,0.6088729763031007,0.6121285653114319,0.6153841543197631,0.6186397433280946,0.6218953323364258,0.625150921344757,0.6284065103530885,0.6316620993614197,0.6349176883697509,0.6381732773780824,0.6414288663864136,0.6446844553947448,0.6479400444030761,0.6511956334114075,0.6544512224197387,0.65770681142807,0.6609624004364014,0.6642179894447326,0.6674735784530639,0.6707291674613953,0.6739847564697266,0.6772403454780578,0.6804959344863892,0.6837515234947205,0.6870071125030517,0.6902627015113831,0.6935182905197144,0.6967738795280456,0.700029468536377,0.7032850575447083,0.7065406465530395,0.709796235561371,0.7130518245697022,0.7163074135780334,0.7195630025863649,0.7228185915946961,0.7260741806030273,0.7293297696113585,0.73258535861969,0.7358409476280212,0.7390965366363524,0.7423521256446839,0.7456077146530151,0.7488633036613463,0.7521188926696778,0.755374481678009,0.7586300706863403,0.7618856596946717,0.7651412487030029,0.7683968377113342,0.7716524267196656,0.7749080157279968,0.7781636047363281,0.7814191937446595,0.7846747827529907,0.787930371761322,0.7911859607696534,0.7944415497779846,0.7976971387863159,0.8009527277946473,0.8042083168029786,0.8074639058113098,0.810719494819641,0.8139750838279725,0.8172306728363037,0.8204862618446349,0.8237418508529664,0.8269974398612976,0.8302530288696288,0.8335086178779603,0.8367642068862915,0.8400197958946227,0.8432753849029542,0.8465309739112854,0.8497865629196166,0.8530421519279481,0.8562977409362793,0.8595533299446105,0.862808918952942,0.8660645079612732,0.8693200969696044,0.8725756859779359,0.8758312749862671,0.8790868639945983,0.8823424530029298,0.885598042011261,0.8888536310195922,0.8921092200279235,0.8953648090362549,0.8986203980445862,0.9018759870529174,0.9051315760612488,0.9083871650695801,0.9116427540779113,0.9148983430862427,0.918153932094574,0.9214095211029052,0.9246651101112366,0.9279206991195679,0.9311762881278991,0.9344318771362305,0.9376874661445618,0.940943055152893,0.9441986441612245,0.9474542331695557,0.9507098221778869,0.9539654111862184,0.9572210001945496,0.9604765892028808,0.9637321782112123,0.9669877672195435,0.9702433562278747,0.973498945236206,0.9767545342445374,0.9800101232528686,0.9832657122611999,0.9865213012695313,0.9897768902778625,0.9930324792861938,0.9962880682945252,0.9995436573028564,1.0027992463111877,1.0060548353195191,1.0093104243278503,1.0125660133361816,1.015821602344513,1.0190771913528442,1.0223327803611755,1.025588369369507,1.0288439583778382,1.0320995473861694,1.0353551363945008,1.038610725402832,1.0418663144111633,1.0451219034194947,1.048377492427826,1.0516330814361572,1.0548886704444884,1.0581442594528199,1.061399848461151,1.0646554374694823,1.0679110264778138,1.071166615486145,1.0744222044944762,1.0776777935028077,1.080933382511139,1.0841889715194701,1.0874445605278016],\"xaxis\":\"x\",\"y\":[0.13541324813779101,0.13794786216534913,0.14048917578937714,0.1430370611433816,0.1455914760536497,0.14815246739424573,0.1507201742149601,0.15329483062326618,0.15587676840174147,0.15846641934290245,0.16106431728399312,0.16367109982495934,0.16628750971362463,0.1689143958829742,0.17155271412643544,0.17420352739813175,0.17686800572625974,0.1795474257290222,0.18224316972391108,0.18495672442259523,0.18768967920520832,0.19044372396945675,0.1932206465516701,0.19602232971868666,0.1988507477313021,0.20170796248191128,0.20459611921091136,0.20751744180842815,0.21047422770995067,0.2134688423965051,0.21650371351206893,0.219581324612989,0.22270420856623696,0.22587494061538493,0.22909613113520028,0.23237041809774822,0.23570045927481548,0.23908892420334396,0.2425384859423515,0.24605181265152634,0.24963155902329004,0.25328035760161655,0.2570008100222709,0.26079547821036786,0.26466687557224133,0.2686174582195544,0.27264961626434264,0.27676566522428275,0.28096783757787547,0.2852582745094516,0.2896390178839198,0.2941120024909734,0.2986790485980756,0.30334185485090687,0.30810199155911516,0.31296089440414776,0.3179198586046441,0.32298003357336136,0.3281424180978698,0.3334078560753059,0.33877703282930377,0.34425047203486614,0.34982853327435526,0.3555114102450365,0.361299129635669,0.36719155068652287,0.3731883654439511,0.3792890997172445,0.38549311474195413,0.3917996095502542,0.3982076240451719,0.40471604277171735,0.41132359937410534,0.41802888172436303,0.42483033770373196,0.4317262816143983,0.4387149011952213,0.44579426521135707,0.452962331583958,0.46021695602251833,0.46755590111896767,0.47497684585927835,0.4824773955051959,0.49005509179574946,0.49770742341544916,0.5054318366735705,0.5132257463366923,0.521086546554667,0.5290116218185442,0.5369983578876001,0.5450441526215923,0.5531464266536656,0.5613026338389978,0.5695102714142932,0.5777668898036276,0.5860701020069226,0.5944175925084779,0.6028071256445285,0.6112365533707129,0.6197038223726486,0.6282069804654777,0.6367441822313054,0.6453136938468477,0.653913897057383,0.6625432922571644,0.6712005006408777,0.679884265395436,0.6885934519063712,0.697327046958342,0.7060841569147426,0.7148640048670647,0.7236659267505342,0.7324893664285164,0.7413338697543214,0.7501990776251991,0.7590847180495849,0.7679905972548742,0.7769165898692442,0.7858626282171968,0.7948286907745526,0.8038147898345648,0.8128209584425573,0.8218472366620428,0.8308936572405682,0.839960230748544,0.8490469302690135,0.8581536757206398,0.8672803179001806,0.8764266223342152,0.8855922530330426,0.8947767562422358,0.903979544289527,0.9131998796262661,0.9224368591638114,0.9316893990056936,0.9409562196764,0.9502358319469545,0.9595265233562973,0.9688263455256546,0.9781331023607106,0.9874443392334111,0.9967573332316845,1.0060690845612372,1.0153763091788963,1.0246754327317646,1.033962585870702,1.0432336010004244,1.0524840105218183,1.061709046614924,1.0709036426035263,1.0800624359343858,1.0891797727959265,1.0982497143927095,1.107266044883281,1.1162222809800573,1.1251116832008794,1.1339272687526893,1.142661826018628,1.1513079306106813,1.159857962940909,1.1683041272553358,1.1766384720657919,1.1848529119064433,1.1929392503334901,1.2008892040785928,1.2086944282590388,1.2163465425405884,1.2238371581423066,1.2311579055666448,1.2383004629324754,1.245256584783967,1.2520181312438452,1.2585770973761141,1.264925642620354,1.2710561201576636,1.2769611060668615,1.2826334281289942,1.2880661941383194,1.2932528195788997,1.2981870545276342,1.3028630096470917,1.3072751811347445,1.3114184744992545,1.315288227039212,1.3188802289052375,1.3221907426324973,1.3252165210375386,1.3279548233807745,1.330403429704019,1.3325606532609977,1.3344253509678419,1.335996931810067,1.3372753631524097,1.3382611749081263,1.338955461534811,1.339359881834501,1.339476656546692,1.3393085637337758,1.3388589319694002,1.3381316313511493,1.3371310623697494,1.335862142677648,1.3343302918102384,1.3325414139231222,1.3305018786185934,1.3282184999439024,1.325698513652789,1.322949552830218,1.3199796219880815,1.316797069746948,1.3134105602255726,1.309829043265829,1.3060617236260432,1.3021180292801984,1.2980075789643182,1.293740149114341,1.2893256403420266,1.2847740435969524,1.2800954061632408,1.2752997976396279,1.270397276050518,1.2653978542340378,1.260311466650667,1.2551479367528853,1.2499169450523988,1.2446279980169976,1.2392903979239118,1.2339132137907374,1.2285052534986762,1.223075037215949,1.2176307722218873,1.2121803292244304,1.2067312202556133,1.2012905782210956,1.1958651381710732,1.1904612203508804,1.185084715080461,1.179741069502617,1.1744352762305879,1.169171863916229,1.16395488975072,1.1587879339005633,1.1536740958726006,1.14861599279291,1.143615759575844,1.1386750509511474,1.1337950453090997,1.1289764503159847,1.1242195102449537,1.1195240149605472,1.1148893104887734,1.110314311098804,1.1057975128169337,1.1013370082886622,1.0969305029004033,1.0925753320685925,1.0882684796007416,1.0840065970303403,1.0797860238254056,1.0756028083689464,1.0714527296086007,1.0673313192722511,1.063233884546489,1.0591555311153749,1.055091186457986,1.0510356233048128,1.0469834831550175,1.0429292997589803,1.0388675224733832,1.0347925393992254,1.0306987002166963,1.026580338634646,1.022431794376513,1.0182474346288937,1.0140216748835327,1.0097489991082496,1.005423979187238,1.0010412935761746,0.9965957451227245,0.9920822780081837,0.9874959937712126,0.9828321663798275,0.9780862563229977,0.9732539236983234,0.9683310402773304,0.9633137005348701,0.9581982316339437,0.9529812023619616,0.9476594310189848,0.942229992262835,0.9366902229201365,0.9310377267762976,0.9252703783611798,0.9193863257507142,0.913383992408006,0.9072620780904871,0.901019558852489,0.8946556861751246,0.8881699852576692,0.8815622525066606,0.8748325522607321,0.8679812127907244,0.8610088216159193,0.8539162201782937,0.8467044979175185,0.8393749857900147,0.8319292492757608,0.8243690809167094,0.8166964924306345,0.8089137064440051,0.8010231478870599,0.7930274350936947,0.7849293706480133,0.7767319320185062,0.7684382620197983,0.7600516591407367,0.7515755677763315,0.7430135683996651,0.7343693677084411,0.7256467887792776,0.7168497612612188,0.7079823116382941,0.6990485535891833,0.6900526784702997,0.6809989459468138,0.6718916747943077,0.6627352338919332,0.6535340334261275,0.6442925163221227,0.6350151499186627,0.6257064178996077,0.6163708124943188,0.6070128269570212,0.5976369483336981,0.5882476505234245,0.578849387639508,0.5694465876743035,0.5600436464701342,0.5506449219973731,0.5412547289394751,0.5318773335834887,0.5225169490134861,0.5131777306032311,0.5038637718034812,0.49457910021838103,0.4853276739646039,0.4761133783061704,0.46694002255722644,0.4578113372444699,0.44873097152047964,0.4397024908187538,0.43072937474094947,0.4218150151665894,0.41296271457529043,0.40417568457148917,0.3954570446015954,0.38680982085353366,0.3782369453287093,0.36974125507660954,0.36132549158241467,0.35299230029826023,0.34474423030907697,0.336583734124271,0.32851316758684285,0.32053478989198464,0.31265076370755884,0.3048631553893449,0.297173935284361,0.2895849781160473,0.2820980634455676,0.27471487620393154,0.2674370072901438,0.26026595423100807,0.2532031218986791,0.24624982328248507,0.23940728031195185,0.2326766247283391,0.22605889900238865,0.21955505729628963,0.21316596646819191,0.2068924071178649,0.20073507467234208,0.1946945805105831,0.1887714531263781,0.18296613932882846,0.17727900547984202,0.17171033876815245,0.1662603485193782,0.16092916754164127,0.1557168535062201,0.15062339036263744,0.1456486897874825,0.14079259266613642,0.13605487060641988,0.13143522748300895,0.12693330101126027,0.12254866434889976,0.11828082772378884,0.11412924008576575,0.11009329078032377,0.10617231124165467,0.10236557670234893,0.0986723079168262,0.0950916728953501,0.09162278864526899,0.08826472291595608,0.08501649594373378,0.08187708219293387,0.07884541208912142,0.07592037374041806,0.0731008146427907,0.07038554336515301,0.06777333121011721,0.06526291384627579,0.06285299290796774,0.06054223755858957,0.05832928601365922,0.056212747020024434,0.054191201287826674,0.0522632028720859,0.05042728050106117,0.048681938848865104,0.04702565975016354,0.04545690335517103,0.043974109223567585,0.04257569735638773,0.041260069165389435,0.040025608379879465,0.03887068189145578,0.03779364053761869,0.03679281982570602,0.035866540599104844,0.03501310964819413,0.0342308202689643,0.033517952772742686,0.03287277495091957,0.03229354249901953,0.03177849940488628,0.031325878306146575,0.030933900822486825,0.030600777868605,0.030324709953996075,0.030103887475978214,0.02993649101257623,0.029820691622036058,0.02975465115585558,0.029736522592274436,0.029764450397170697,0.029836570919262687,0.02995101282640937,0.030105897589641686,0.030299340021341582,0.03052944887371276,0.030794327503361748,0.031092074607428754,0.031420785036276655,0.03177855068726731,0.03216346148362847,0.032573606441843816,0.03300707483039006,0.033461957421997694,0.03393634784093383,0.03442834400609847,0.0349360496699962,0.03545757605289585,0.035991043570729644,0.03653458365451302,0.03708634065829448,0.03764447385187368,0.03820715949376663,0.038772592979148465,0.03933899105677664,0.0399045941081951,0.04046766848184753,0.04102650887409097,0.04157944074850423,0.042124822784336345,0.04266104934443629,0.04318655295256028,0.04369980676956238,0.044199327057644434,0.044683675621578905,0.04515146221561893,0.04560134690468109,0.04603204236832748,0.04644231613608798,0.04683099274274642,0.04719695579237347,0.04753914992011755,0.04785658264106525,0.04814832607585291,0.048413518543147536,0.048651366009619126,0.04886114338858967,0.04904219567916948,0.04919393893836974,0.04931586107941025,0.04940752249021829,0.04946855646693255,0.04949866945808087],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"legendgroup\":\"generator\",\"marker\":{\"color\":\"rgb(255, 127, 14)\"},\"mode\":\"lines\",\"name\":\"generator\",\"showlegend\":false,\"x\":[0.015400712378323078,0.01652271377854049,0.017644715178757906,0.018766716578975322,0.019888717979192734,0.021010719379410146,0.022132720779627562,0.023254722179844978,0.02437672358006239,0.025498724980279802,0.026620726380497218,0.027742727780714634,0.028864729180932046,0.029986730581149458,0.031108731981366874,0.03223073338158429,0.0333527347818017,0.034474736182019114,0.035596737582236526,0.03671873898245394,0.03784074038267136,0.03896274178288877,0.04008474318310619,0.0412067445833236,0.042328745983541013,0.043450747383758426,0.04457274878397584,0.04569475018419325,0.04681675158441067,0.04793875298462808,0.049060754384845494,0.050182755785062906,0.051304757185280325,0.05242675858549774,0.05354875998571515,0.05467076138593256,0.05579276278614998,0.05691476418636739,0.058036765586584806,0.05915876698680222,0.06028076838701964,0.06140276978723705,0.06252477118745446,0.06364677258767187,0.0647687739878893,0.0658907753881067,0.06701277678832412,0.06813477818854152,0.06925677958875895,0.07037878098897636,0.07150078238919377,0.07262278378941119,0.0737447851896286,0.07486678658984602,0.07598878799006342,0.07711078939028085,0.07823279079049826,0.07935479219071567,0.08047679359093309,0.0815987949911505,0.08272079639136791,0.08384279779158532,0.08496479919180273,0.08608680059202016,0.08720880199223757,0.08833080339245498,0.0894528047926724,0.09057480619288981,0.09169680759310722,0.09281880899332463,0.09394081039354205,0.09506281179375947,0.09618481319397688,0.0973068145941943,0.09842881599441171,0.09955081739462912,0.10067281879484653,0.10179482019506395,0.10291682159528136,0.10403882299549877,0.1051608243957162,0.10628282579593361,0.10740482719615102,0.10852682859636843,0.10964882999658584,0.11077083139680326,0.11189283279702067,0.11301483419723808,0.11413683559745551,0.11525883699767292,0.11638083839789033,0.11750283979810774,0.11862484119832516,0.11974684259854257,0.12086884399875998,0.1219908453989774,0.12311284679919482,0.12423484819941223,0.12535684959962964,0.12647885099984707,0.12760085240006447,0.12872285380028187,0.1298448552004993,0.13096685660071672,0.13208885800093412,0.13321085940115154,0.13433286080136897,0.13545486220158637,0.13657686360180377,0.1376988650020212,0.13882086640223862,0.13994286780245602,0.14106486920267344,0.14218687060289084,0.14330887200310827,0.14443087340332567,0.1455528748035431,0.14667487620376052,0.14779687760397792,0.14891887900419534,0.15004088040441274,0.15116288180463017,0.15228488320484757,0.153406884605065,0.1545288860052824,0.15565088740549982,0.15677288880571724,0.15789489020593464,0.15901689160615207,0.16013889300636946,0.1612608944065869,0.1623828958068043,0.16350489720702172,0.1646268986072391,0.16574890000745654,0.16687090140767397,0.16799290280789136,0.1691149042081088,0.1702369056083262,0.17135890700854362,0.172480908408761,0.17360290980897844,0.17472491120919587,0.17584691260941326,0.1769689140096307,0.1780909154098481,0.17921291681006551,0.1803349182102829,0.18145691961050034,0.18257892101071774,0.18370092241093516,0.1848229238111526,0.18594492521137,0.18706692661158741,0.1881889280118048,0.18931092941202224,0.19043293081223964,0.19155493221245706,0.19267693361267446,0.1937989350128919,0.1949209364131093,0.1960429378133267,0.19716493921354414,0.19828694061376154,0.19940894201397896,0.20053094341419636,0.2016529448144138,0.2027749462146312,0.2038969476148486,0.20501894901506604,0.20614095041528344,0.20726295181550086,0.20838495321571826,0.2095069546159357,0.21062895601615308,0.2117509574163705,0.21287295881658794,0.21399496021680534,0.21511696161702276,0.21623896301724016,0.21736096441745759,0.21848296581767498,0.2196049672178924,0.2207269686181098,0.22184897001832724,0.22297097141854466,0.22409297281876206,0.22521497421897949,0.22633697561919688,0.2274589770194143,0.2285809784196317,0.22970297981984913,0.23082498122006656,0.23194698262028396,0.23306898402050139,0.23419098542071878,0.2353129868209362,0.2364349882211536,0.23755698962137103,0.23867899102158843,0.23980099242180586,0.24092299382202328,0.24204499522224068,0.2431669966224581,0.2442889980226755,0.24541099942289293,0.24653300082311033,0.24765500222332776,0.24877700362354516,0.24989900502376258,0.25102100642398,0.2521430078241974,0.25326500922441486,0.2543870106246322,0.25550901202484966,0.25663101342506706,0.25775301482528445,0.2588750162255019,0.2599970176257193,0.2611190190259367,0.26224102042615416,0.26336302182637156,0.26448502322658896,0.26560702462680635,0.2667290260270238,0.2678510274272412,0.2689730288274586,0.27009503022767606,0.27121703162789346,0.27233903302811086,0.27346103442832825,0.2745830358285457,0.2757050372287631,0.2768270386289805,0.27794904002919796,0.27907104142941536,0.28019304282963275,0.28131504422985015,0.2824370456300676,0.283559047030285,0.2846810484305024,0.2858030498307198,0.28692505123093726,0.28804705263115465,0.28916905403137205,0.2902910554315895,0.2914130568318069,0.2925350582320243,0.2936570596322417,0.29477906103245916,0.29590106243267655,0.29702306383289395,0.2981450652331114,0.2992670666333288,0.3003890680335462,0.3015110694337636,0.30263307083398105,0.30375507223419845,0.30487707363441585,0.3059990750346333,0.3071210764348507,0.3082430778350681,0.3093650792352855,0.31048708063550295,0.31160908203572035,0.31273108343593775,0.31385308483615515,0.3149750862363726,0.31609708763659,0.3172190890368074,0.31834109043702485,0.31946309183724225,0.32058509323745965,0.32170709463767705,0.3228290960378945,0.3239510974381119,0.3250730988383293,0.32619510023854675,0.32731710163876415,0.32843910303898155,0.32956110443919895,0.3306831058394164,0.3318051072396338,0.3329271086398512,0.33404911004006865,0.33517111144028605,0.33629311284050345,0.33741511424072085,0.3385371156409383,0.3396591170411557,0.3407811184413731,0.3419031198415905,0.34302512124180795,0.34414712264202535,0.34526912404224275,0.3463911254424602,0.3475131268426776,0.348635128242895,0.3497571296431124,0.35087913104332985,0.35200113244354725,0.35312313384376465,0.3542451352439821,0.3553671366441995,0.3564891380444169,0.3576111394446343,0.35873314084485175,0.35985514224506915,0.36097714364528655,0.362099145045504,0.3632211464457214,0.3643431478459388,0.3654651492461562,0.36658715064637365,0.36770915204659105,0.36883115344680845,0.36995315484702584,0.3710751562472433,0.3721971576474607,0.3733191590476781,0.37444116044789555,0.37556316184811295,0.37668516324833035,0.37780716464854774,0.3789291660487652,0.3800511674489826,0.3811731688492,0.38229517024941745,0.38341717164963485,0.38453917304985225,0.38566117445006964,0.3867831758502871,0.3879051772505045,0.3890271786507219,0.39014918005093935,0.39127118145115675,0.39239318285137414,0.39351518425159154,0.394637185651809,0.3957591870520264,0.3968811884522438,0.3980031898524612,0.39912519125267865,0.40024719265289604,0.40136919405311344,0.4024911954533309,0.4036131968535483,0.4047351982537657,0.4058571996539831,0.40697920105420055,0.40810120245441794,0.40922320385463534,0.4103452052548528,0.4114672066550702,0.4125892080552876,0.413711209455505,0.41483321085572245,0.41595521225593984,0.41707721365615724,0.4181992150563747,0.4193212164565921,0.4204432178568095,0.4215652192570269,0.42268722065724434,0.42380922205746174,0.42493122345767914,0.42605322485789654,0.427175226258114,0.4282972276583314,0.4294192290585488,0.43054123045876624,0.43166323185898364,0.43278523325920104,0.43390723465941844,0.4350292360596359,0.4361512374598533,0.4372732388600707,0.43839524026028814,0.43951724166050554,0.44063924306072294,0.44176124446094034,0.4428832458611578,0.4440052472613752,0.4451272486615926,0.44624925006181004,0.44737125146202744,0.44849325286224484,0.44961525426246224,0.4507372556626797,0.4518592570628971,0.4529812584631145,0.4541032598633319,0.45522526126354934,0.45634726266376674,0.45746926406398414,0.4585912654642016,0.459713266864419,0.4608352682646364,0.4619572696648538,0.46307927106507124,0.46420127246528864,0.46532327386550604,0.4664452752657235,0.4675672766659409,0.4686892780661583,0.4698112794663757,0.47093328086659314,0.47205528226681054,0.47317728366702794,0.4742992850672454,0.4754212864674628,0.4765432878676802,0.4776652892678976,0.47878729066811504,0.47990929206833244,0.48103129346854984,0.48215329486876723,0.4832752962689847,0.4843972976692021,0.4855192990694195,0.48664130046963694,0.48776330186985434,0.48888530327007174,0.49000730467028913,0.4911293060705066,0.492251307470724,0.4933733088709414,0.49449531027115884,0.49561731167137624,0.49673931307159364,0.49786131447181103,0.4989833158720285,0.5001053172722458,0.5012273186724633,0.5023493200726807,0.5034713214728981,0.5045933228731155,0.505715324273333,0.5068373256735503,0.5079593270737678,0.5090813284739852,0.5102033298742026,0.51132533127442,0.5124473326746375,0.5135693340748548,0.5146913354750723,0.5158133368752896,0.5169353382755071,0.5180573396757245,0.5191793410759419,0.5203013424761593,0.5214233438763768,0.5225453452765941,0.5236673466768116,0.524789348077029,0.5259113494772464,0.5270333508774638,0.5281553522776812,0.5292773536778986,0.5303993550781161,0.5315213564783334,0.5326433578785509,0.5337653592787683,0.5348873606789857,0.5360093620792031,0.5371313634794206,0.5382533648796379,0.5393753662798554,0.5404973676800728,0.5416193690802902,0.5427413704805076,0.543863371880725,0.5449853732809424,0.5461073746811599,0.5472293760813772,0.5483513774815947,0.5494733788818121,0.5505953802820295,0.5517173816822469,0.5528393830824644,0.5539613844826817,0.5550833858828992,0.5562053872831165,0.557327388683334,0.5584493900835514,0.5595713914837688,0.5606933928839862,0.5618153942842037,0.562937395684421,0.5640593970846385,0.5651813984848559,0.5663033998850733,0.5674254012852907,0.5685474026855082,0.5696694040857255,0.570791405485943,0.5719134068861603,0.5730354082863778,0.5741574096865952,0.5752794110868126],\"xaxis\":\"x\",\"y\":[0.32936740496410555,0.33476269514848445,0.3401523176811842,0.34553538548553675,0.35091115278762186,0.3562790205238776,0.3616385414282671,0.3669894247770093,0.3723315407696298,0.3776649245259338,0.3829897796794519,0.3883064815489667,0.39361557987087414,0.39891780107640024,0.4042140500990366,0.40950541169901516,0.4147931512931863,0.4200787152802948,0.4253637308533701,0.4306500052927465,0.4359395247351122,0.44123445241591414,0.4465371263844811,0.4518500566932653,0.45717592206473473,0.4625175660415893,0.46787799262816315,0.4732603614330744,0.4786679823253947,0.48410430961883333,0.48957293580062705,0.49507758482400593,0.5006221049852565,0.5062104614085002,0.511846728163351,0.5175350800425795,0.5232797840288075,0.5290851904810419,0.5349557240735476,0.5408958745211185,0.5469101871262373,0.5530032531849105,0.559179700289093,0.5654441825645842,0.5718013708840796,0.5782559430956673,0.5848125743074661,0.5914759272693466,0.5982506428926504,0.6051413309486472,0.6121525609860492,0.6192888535072455,0.62655467144208,0.6339544119569085,0.6414923986353521,0.6491728740656733,0.6569999928679242,0.6649778151921024,0.6731103007163689,0.6814013031720504,0.6898545654196035,0.698473715097009,0.7072622608591793,0.7162235892239515,0.7253609620370504,0.7346775145651538,0.7441762542227661,0.7538600599351847,0.763731682136257,0.7737937433960893,0.7840487396702237,0.7944990421582236,0.8051468997559867,0.8159944420825735,0.8270436830588369,0.8382965250117386,0.8497547632749389,0.8614200912530672,0.8732941059140765,0.8853783136712127,0.8976741366134835,0.9101829190410521,0.9229059342597593,0.9358443915869955,0.9489994435194171,0.9623721930115609,0.9759637008132422,0.9897749928127464,1.0038070673322876,1.0180609023219074,1.0325374623981152,1.0472377056738957,1.0621625903274525,1.0773130808580618,1.0926901539787568,1.108294804097197,1.1241280483380416,1.1401909310623723,1.1564845278422404,1.1730099488511836,1.1897683416346116,1.206760893227205,1.2239888315879672,1.2414534263272192,1.2591559887036954,1.2770978708738385,1.2952804643795355,1.3137051978647034,1.3323735340154226,1.3512869657225826,1.3704470114703637,1.3898552099581467,1.4095131139677082,1.4294222834917387,1.4495842781438262,1.4700006488739634,1.4906729290175074,1.5116026247090815,1.5327912046964114,1.554240089592235,1.57595064060545,1.5979241477953126,1.6201618178949742,1.642664761752761,1.6654339814414187,1.6884703570870705,1.7117746334708108,1.735347406456738,1.7591891093007146,1.7832999988943656,1.8076801419986643,1.8323294015209888,1.8572474228887472,1.882433620571541,1.9078871648024813,1.9336069685475186,1.9595916747697606,1.9858396440334911,2.0123489424901897,2.039117330286207,2.0661422504289133,2.0934208181451655,2.1209498107627947,2.1487256581426255,2.176744433685201,2.2050018459330754,2.2334932307861504,2.2622135443441787,2.2911573563872625,2.320318844501888,2.349691788856962,2.3792695676311983,2.4090451530904224,2.4390111083105905,2.469159584539855,2.499482319190735,2.5299706344513546,2.560615436502992,2.5914072153295944,2.6223360451037387,2.6533915851325216,2.6845630813462282,2.7158393683123117,2.7472088717571306,2.778659611578194,2.810179205330156,2.8417548721687442,2.8733734372378614,2.905021336486496,2.936684621903764,2.9683489671622425,2.9999996736618644,3.0316216769689,3.063199553647011,3.0947175284798893,3.1261594820877665,3.1575089589426986,3.188749175790417,3.2198630304893614,3.2508331112801723,3.2816417065017855,3.3122708147727993,3.342702155659312,3.3729171808528235,3.402897085883821,3.432622822398733,3.462075111029456,3.4912344548861567,3.520081153704994,3.548595318683207,3.576756888034342,3.6045456432963103,3.6319412264246087,3.6589231577021235,3.685470854495635,3.711563650887514,3.737180818208768,3.7623015864971237,3.786905166900702,3.8109707750443063,3.8344776553715088,3.8574051064712473,3.8797325073929936,3.9014393449493516,3.9225052419994917,3.9429099867009674,3.962633562711372,3.981656180314867,3.999958308441974,4.01752070754427,4.034324463278544,4.050351020947988,4.0655822206407715,4.0800003329991945,4.093588095545528,4.106328749483485,4.118206076887405,4.129204438184484,4.139308809828759,4.1485048220594285,4.156778796630026,4.1641177843895285,4.170509602591251,4.175942871800771,4.180407052269893,4.183892479640098,4.186390399835885,4.187893003005938,4.188393456368364,4.187885935815107,4.186365656130268,4.183828899677445,4.180273043412233,4.175696584077894,4.170099161444812,4.163481579457693,4.155845825158613,4.147195085258909,4.1375337602385285,4.126867475857883,4.115203091974257,4.102548708562709,4.088913668849788,4.074308559477505,4.05874520762467,4.0422366750230045,4.024797248816111,4.006442429220722,3.987188913961211,3.9670545794604486,3.9460584587823253,3.9242207163339624,3.9015626193482884,3.878106506180669,3.8538757514661857,3.8288947281971817,3.8031887667936117,3.7767841112514793,3.749707872467345,3.7219879788491412,3.693653124335672,3.6647327139586725,3.6352568070927456,3.605256058548952,3.5747616576781973,3.543805265659936,3.5124189511607535,3.480635124555419,3.4484864709104777,3.4160058819370795,3.3832263871254806,3.3501810842786233,3.3169030696661173,3.2834253680231846,3.249780862621137,3.2160022256372565,3.1821218490521064,3.1481717763016355,3.114183634909651,3.080188570323581,3.046217181172841,3.0122994561644636,2.978464712825217,2.944741538292961,2.911157732352742,2.877740252904994,2.8445151640442647,2.8115075869172066,2.7787416535181677,2.7462404635695856,2.7140260446227487,2.6821193155021454,2.6505400532038883,2.61930686334548,2.588437154250474,2.5579471147377797,2.527851695671053,2.498164595309201,2.4688982484845954,2.440063819620897,2.4116711995878526,2.3837290063758765,2.3562445895588726,2.329224038499553,2.3026721942375485,2.276592664987097,2.2509878451577583,2.2258589377989533,2.2012059803567445,2.177027873619591,2.1533224137186915,2.130086327037972,2.107315307879043,2.085004058717293,2.0631463328770017,2.041734979445806,2.0207619902420935,2.0002185486430544,1.980095080076065,1.9603813039718982,1.9410662869750082,1.9221384972037032,1.9035858593515342,1.8853958104205737,1.86755535587754,1.8500511260248114,1.8328694323803385,1.8159963238632946,1.7994176425858641,1.783119079056002,1.7670862266011165,1.7513046348285184,1.7357598619450005,1.720437525765167,1.705323353245885,1.6904032283926718,1.675663238392661,1.6610897178382364,1.6466692909151646,1.6323889114392685,1.6182359006361675,1.604197982569408,1.5902633171333054,1.5764205305379733,1.5626587432253645,1.5489675951664685,1.5353372685012194,1.5217585074940176,1.5082226357890494,1.4947215709607433,1.481247836365639,1.467794570312746,1.4543555325799118,1.440925108313948,1.4274983093620384,1.4140707730915,1.4006387587639149,1.3871991415383207,1.3737494041862086,1.360287626608738,1.346812473253603,1.3333231785355626,1.3198195303705829,1.3063018519389251,1.2927709817972723,1.2792282524641698,1.2656754676066067,1.2521148779584983,1.2385491561041098,1.2249813702611838,1.2114149571996151,1.1978536944319271,1.1843016718117148,1.170763262675484,1.1572430946619927,1.1437460203413647,1.130277087783841,1.116841511195111,1.1034446417417691,1.0900919386865233,1.0767889409485092,1.0635412391992622,1.0503544485997929,1.0372341822787245,1.0241860256456017,1.0112155116274217,0.9983280969099894,0.9855291392591837,0.9728238759903642,0.9602174036472262,0.9477146589443409,0.9353204010204427,0.9230391950423252,0.9108753971919666,0.8988331410622754,0.886916325479701,0.8751286037648439,0.8634733744352111,0.8519537733474595,0.8405726672697706,0.8293326488685515,0.8182360330874263,0.8072848548904769,0.7964808683360084,0.7858255469416812,0.7753200852967814,0.7649654018726354,0.7547621429777774,0.7447106878004556,0.7348111544773984,0.7250634071245292,0.7154670637624292,0.7060215050669425,0.6967258838732306,0.6875791353600031,0.6785799878394162,0.6697269740773389,0.6610184430682976,0.6524525721894255,0.6440273796581314,0.6357407372190169,0.6275903829867112,0.6195739343728125,0.6116889010270005,0.603932697724568,0.596302657135101,0.5887960424098397,0.5814100595282992,0.574141869348025,0.5669885993048681,0.5599473547149012,0.5530152296329716,0.5461893172269299,0.5394667196307349,0.5328445572439001,0.5263199774490558,0.519890162723789,0.5135523381273139,0.5073037781468843,0.5011418128932409,0.49506383363864864,0.4890672976953034,0.48314973263598243,0.4773087398628048,0.47154199753377185,0.46584726286043804,0.460222373793541,0.4546652501166634,0.44917389397108615,0.4437463898377837,0.438380904005101,0.4330756835529748,0.4278290548865951,0.42263942185420905,0.4175052634852687,0.41242513138633635,0.407397646833131,0.40242149759774465,0.39749543455044867,0.3926182680756287,0.38778886434120846,0.38300614146052153,0.3782690655849108,0.3735766469643994,0.36892793601266227,0.36432201941112147,0.3597580162854549,0.3552350744860062,0.3507523670017009,0.34630908853493264,0.34190445226270083,0.3375376868069125,0.3332080334343243,0.32891474350407546,0.32465707617817313,0.3204342964076605,0.31624567320456004,0.3120904782070021,0.30796798454233465,0.303877465990395,0.29981819644655366,0.29578944968167464,0.29179049939372254,0.2878206195434281,0.28387908496426323,0.2799651722348791,0.2760781608002507,0.2722173343259975,0.26838198226871224,0.264571401643695,0.2607848989701945,0.25702179237317163,0.253281413819659,0.24956311146708327,0.245866252100336,0.2421902236340433,0.2385344376562832,0.23489833199001575,0.23128137324865644,0.22768305936258681],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"legendgroup\":\"rael\",\"marker\":{\"color\":\"rgb(31, 119, 180)\",\"symbol\":\"line-ns-open\"},\"mode\":\"markers\",\"name\":\"rael\",\"showlegend\":false,\"x\":[0.31926533579826355,0.1970769464969635,0.0918283462524414,0.04214535653591156,0.38781440258026123,0.45149990916252136,0.6570965647697449,-0.16994699835777283,0.05970039963722229,0.1312589943408966,0.0894184485077858,0.48843494057655334,-0.11010244488716125,0.09856948256492615,0.0716269463300705,0.3288358747959137,-0.08256645500659943,-0.4083579182624817,0.4074728190898895,0.2674974799156189,-0.3110252320766449,0.2609313130378723,0.5058010816574097,0.3545064330101013,-0.20491209626197815,0.08470205962657928,-0.019575923681259155,0.08613456785678864,0.08869387209415436,-0.030085280537605286,0.17265862226486206,-0.18869686126708984,0.07879428565502167,0.4340452253818512,-0.07059131562709808,-0.0018469244241714478,0.05014371871948242,0.5858950614929199,0.15157881379127502,0.16910795867443085,-0.1486910581588745,0.07999926060438156,-0.10819773375988007,-0.22044184803962708,0.3097939193248749,0.0016308650374412537,0.10859505832195282,0.4524754583835602,0.4831377863883972,-0.5370943546295166,0.3384043872356415,0.09997327625751495,0.15340037643909454,0.3289087116718292,1.0907001495361328,0.1788521707057953,0.3813215494155884,0.2748507261276245,0.5244182348251343,0.5940709710121155,-0.21061784029006958,-0.13652488589286804,0.3958180248737335,-0.4469004273414612],\"xaxis\":\"x\",\"y\":[\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\",\"rael\"],\"yaxis\":\"y2\",\"type\":\"scatter\"},{\"legendgroup\":\"generator\",\"marker\":{\"color\":\"rgb(255, 127, 14)\",\"symbol\":\"line-ns-open\"},\"mode\":\"markers\",\"name\":\"generator\",\"showlegend\":false,\"x\":[0.3750627636909485,0.3234071135520935,0.3011435568332672,0.1783347725868225,0.22536218166351318,0.015400712378323078,0.22065138816833496,0.25865939259529114,0.2853989899158478,0.050407830625772476,0.2753312289714813,0.13464973866939545,0.21381717920303345,0.18111157417297363,0.23170766234397888,0.4279977083206177,0.13508360087871552,0.3777902126312256,0.57640141248703,0.41349196434020996,0.2106437087059021,0.3964504599571228,0.2998558282852173,0.2847467362880707,0.15398472547531128,0.31465256214141846,0.14590299129486084,0.38340049982070923,0.4614834189414978,0.5076261758804321,0.23645830154418945,0.2720438838005066,0.312058687210083,0.2172023057937622,0.3174465596675873,0.30015963315963745,0.11591347306966782,0.2926647961139679,0.2682541012763977,0.2602398991584778,0.25645798444747925,0.29681554436683655,0.26281991600990295,0.31969764828681946,0.22756828367710114,0.3957976698875427,0.2629767954349518,0.07052788138389587,0.35178208351135254,0.28167787194252014,0.5017540454864502,0.2157885581254959,0.22387313842773438,0.292562872171402,0.3120690882205963,0.2784305214881897,0.261816143989563,0.4083458185195923,0.19985023140907288,0.42038148641586304,0.18163830041885376,0.2796711325645447,0.31163734197616577,0.24376320838928223],\"xaxis\":\"x\",\"y\":[\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\",\"generator\"],\"yaxis\":\"y2\",\"type\":\"scatter\"}],                        {\"barmode\":\"overlay\",\"hovermode\":\"closest\",\"legend\":{\"traceorder\":\"reversed\"},\"xaxis\":{\"anchor\":\"y2\",\"domain\":[0.0,1.0],\"zeroline\":false},\"yaxis\":{\"anchor\":\"free\",\"domain\":[0.35,1],\"position\":0.0},\"yaxis2\":{\"anchor\":\"x\",\"domain\":[0,0.25],\"dtick\":1,\"showticklabels\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4f0add28-fd8b-42ed-a70e-663b79da68fc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q6pCrxIwHJy"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, letant_dim: int, im_dim):\n",
        "        super().__init__()\n",
        "        self.im_dim = im_dim\n",
        "        self.len_im = im_dim[0] * im_dim[1]\n",
        "        self.letant_dim = letant_dim\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(letant_dim, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256, self.len_im),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.model(X.view((-1, self.letant_dim))).view((-1, *self.im_dim))\n",
        "\n",
        "\n",
        "class Discrimnator(nn.Module):\n",
        "    def __init__(self, im_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.im_dim = im_dim\n",
        "        self.len_im = im_dim[0] * im_dim[1]\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(self.len_im, 128), nn.LeakyReLU(), nn.Linear(128, 1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.model(X.view(-1, self.len_im)).view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2X5wWW4zRf5"
      },
      "outputs": [],
      "source": [
        "transfomer = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
        "mnist_data = datasets.MNIST(\"/dataset\", download=True, transform=transfomer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRigTOsG9VT0"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9rFVcMlz6N3"
      },
      "outputs": [],
      "source": [
        "letant_dim = 100\n",
        "im_dim = (28, 28)\n",
        "generator = Generator(letant_dim, im_dim).to(device)\n",
        "discrimnator = Discrimnator(im_dim).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4V8TSFKy_py"
      },
      "outputs": [],
      "source": [
        "lr = 3e-4\n",
        "optim_g = optim.Adam(generator.parameters(), lr=lr)\n",
        "optim_d = optim.Adam(discrimnator.parameters(), lr=lr)\n",
        "loss_f = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJUSaZ5h0-f6"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "\n",
        "num_epochs = 32\n",
        "batch_size = 64\n",
        "out_data = pd.DataFrame(\n",
        "    {\"epoch\": pd.NA, \"batch\": pd.NA, \"loss_g\": pd.NA, \"loss_d\": pd.NA},\n",
        "    index=range(num_epochs * ceil(len(mnist_data) / batch_size)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K66ATVud1kj3"
      },
      "outputs": [],
      "source": [
        "\n",
        "ind_out_data = 0\n",
        "for epoch_ind in range(num_epochs):\n",
        "    loader = dataloader.DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
        "    for i_batch, (X, _) in enumerate(loader):\n",
        "        optim_g.zero_grad()\n",
        "        optim_d.zero_grad()\n",
        "        noise = torch.rand(X.shape[0], letant_dim).to(device)\n",
        "        fake = generator(noise)\n",
        "        loss_d_fake = loss_f(discrimnator(fake), torch.zeros(fake.shape[0]).to(device))\n",
        "        loss_d_real = loss_f(\n",
        "            discrimnator(X.to(device)), torch.ones(X.shape[0]).to(device)\n",
        "        )\n",
        "        loss_d = (loss_d_fake + loss_d_real) / 2\n",
        "        loss_d.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "\n",
        "        loss_g = loss_f(discrimnator(fake), torch.ones(fake.shape[0]).to(device))\n",
        "        loss_g.backward()\n",
        "        optim_g.step()\n",
        "        out_data.loc[ind_out_data] = [epoch_ind, i_batch, loss_g.item(), loss_d.item()]\n",
        "        ind_out_data += 1\n",
        "    with torch.no_grad():\n",
        "        noise = torch.rand(10, letant_dim)\n",
        "        im = generator(noise.to(device))\n",
        "        clear_output(wait=True)\n",
        "        px.imshow(im.cpu().detach(), facet_col=0, facet_col_wrap=5).show()\n",
        "        px.line(out_data, x=\"batch\", y=\"loss_g\", color=\"epoch\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-cTCXaS-Dna"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "from IPython.display import clear_output\n",
        "\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "out_data = pd.DataFrame(\n",
        "    {\"epochs\": pd.NA, \"batch\": pd.NA, \"loss_g\": pd.NA, \"loss_d\": pd.NA},\n",
        "    index=range(num_epochs * ceil(len(mnist_data) / batch_size)),\n",
        ")\n",
        "index_data = 0\n",
        "for epoch in range(num_epochs):\n",
        "    loader = dataloader.DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
        "    for batch_i, (X, _) in enumerate(loader):\n",
        "        curr_batch_size = X.shape[0]\n",
        "\n",
        "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "        noise = torch.randn(curr_batch_size, letant_dim).to(device)\n",
        "        fake = generator(noise)\n",
        "        disc_real = discrimnator(X.to(device)).view(-1)\n",
        "        lossD_real = loss_f(disc_real, torch.ones_like(disc_real).to(device))\n",
        "        disc_fake = discrimnator(fake).view(-1)\n",
        "        lossD_fake = loss_f(disc_fake, torch.zeros_like(disc_fake).to(device))\n",
        "        lossD = (lossD_real + lossD_fake) / 2\n",
        "        optim_d.zero_grad()\n",
        "        lossD.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "\n",
        "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "        # where the second option of maximizing doesn't suffer from\n",
        "        # saturating gradients\n",
        "        output = discrimnator(fake).view(-1)\n",
        "        lossG = loss_f(output, torch.ones_like(output).to(device))\n",
        "        optim_g.zero_grad()\n",
        "        lossG.backward()\n",
        "        optim_g.step()\n",
        "\n",
        "        out_data.loc[index_data] = [epoch, batch_i, lossG.item(), lossD.item()]\n",
        "        index_data += 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(torch.rand(10, 100).to(device))\n",
        "        clear_output(wait=True)\n",
        "        px.imshow(fake.cpu().detach(), facet_col=0, facet_col_wrap=5).show()\n",
        "        px.line(out_data, x=\"batch\", y=[\"loss_g\"], color=\"epochs\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpnVR8ry66Yi"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchvision plotly black[jupyter] tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y6bger-7ZT3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import dataloader\n",
        "from torchvision import transforms, datasets\n",
        "from plotly import express as px, graph_objects as go\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrukyl_y0b2c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXlVnKwqm5Ey"
      },
      "outputs": [],
      "source": [
        "# !black '/content/drive/MyDrive/gan_for_Day/chang_train_ratio_6/update_in_run_time_6.ipynb'\n",
        "# !black '/content/drive/MyDrive/Colab Notebooks/gan_for_Day/chang_train_ratio_6/update_in_run_time_6.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cIClnPN7aqp"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "ImageDimType = Tuple[int, int]\n",
        "ImageType = torch.Tensor\n",
        "TensorType = torch.Tensor\n",
        "DataSetVisionType = datasets.vision.VisionDataset\n",
        "LossFunctionType = nn.modules.loss._WeightedLoss\n",
        "OptimizerType = optim.Optimizer\n",
        "DeviceType = str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m23ppIqefGDf"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "##  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JReS6LtM4XDz"
      },
      "outputs": [],
      "source": [
        "f = lambda x:  x**2 + 10\n",
        "X = (torch.randn(1000)-0.5)*10\n",
        "y = f(X)\n",
        "Xy = torch.stack([X,y]) # 2x1000,on the first row is X, on the second row is y\n",
        "data = Xy.T             # 1000x2, every row is a sample\n",
        "px.scatter(x=Xy[0],y=Xy[1]).show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC4xo82tfs_E"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "##  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psVcCbDo4XD0"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(32, 2),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9WmTri8MO38"
      },
      "outputs": [],
      "source": [
        "px.scatter(*Generator()(torch.randn(10000, 2)).detach().T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBkOV6Sz4XD1"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVhiVCYn4XD1"
      },
      "outputs": [],
      "source": [
        "Discriminator()(torch.randn(10,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_7rbf0B7frl"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "discriminator = Discriminator().to(device)\n",
        "generator = Generator().to(device)\n",
        "optim_d = optim.Adam(Discriminator().parameters())\n",
        "optim_g = optim.Adam(Generator().parameters())\n",
        "loss_fn = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFt9WRIOf1GV"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "## "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPUV6AAG4XD2"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "epochs = 300\n",
        "batch_size = 64\n",
        "num_batch = ceil(len(data)/batch_size)\n",
        "record_data = pd.DataFrame(\n",
        "    {\"epoch\": int(), \"batch\": int(), \"loss_d\": float(), \"loss_g\": float()},\n",
        "    index=range(epochs * num_batch),\n",
        ")\n",
        "example_gen = torch.empty(epochs,10,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65WsO9Ed4XD2"
      },
      "outputs": [],
      "source": [
        "run_ind = 0\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    data_loader = dataloader.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "    for batch_ind, points in enumerate(data_loader):\n",
        "        points = points.to(device)\n",
        "        # Train discriminator\n",
        "        optim_d.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 2, device=device))\n",
        "        loss_d = loss_fn(\n",
        "            discriminator(points), torch.ones(len(points),1, device=device)\n",
        "        )\n",
        "        loss_d += loss_fn(\n",
        "            discriminator(fake), torch.zeros(len(points),1, device=device)\n",
        "        )\n",
        "        loss_d.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "        # Train generator\n",
        "        optim_g.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 2, device=device))\n",
        "        loss_g = loss_fn(discriminator(fake), torch.ones(len(points),1, device=device))\n",
        "        loss_g.backward()\n",
        "        optim_g.step()\n",
        "        # Record losses\n",
        "        record_data.iloc[run_ind] = epoch, batch_ind, loss_d.item(), loss_g.item()\n",
        "        run_ind += 1\n",
        "    clear_output(wait=True)\n",
        "    with torch.no_grad():\n",
        "        example_gen[epoch] = generator(torch.rand(10,2,device=device)).detach().cpu()\n",
        "px.line(\n",
        "    record_data, x=\"batch\", y=[\"loss_d\", \"loss_g\"], animation_frame=\"epoch\"\n",
        ").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP2bWlWr__Kx"
      },
      "outputs": [],
      "source": [
        "example_gen = example_gen.transpose(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITeZLVTn_rM2"
      },
      "outputs": [],
      "source": [
        "# @title { run: \"auto\" }\n",
        "ind = 279 # @param {type:\"slider\", min:0, max:299, step:1}\n",
        "px.scatter(x=example_gen[ind,0],y=example_gen[ind,1]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Pr8-ZlB7Xj"
      },
      "outputs": [],
      "source": [
        "px.scatter(example_gen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw8vIbohqIVo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "var, mean = random.randint(0, 10), random.randint(0, 10)\n",
        "p_real = (torch.randn(10000) * var + mean).reshape(-1, 1)\n",
        "bin_centers, bin_count = torch.histogram(p_real, bins=30, density=True)\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=bin_count,\n",
        "            y=bin_centers,\n",
        "            mode=\"lines\",\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n8F3AbZqIVo"
      },
      "outputs": [],
      "source": [
        "class D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(1, 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(2, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "class G(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(1, 1),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "line = torch.linspace(-10,10,10).reshape(-1,1)\n",
        "print(G()(line))\n",
        "print(D()(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c-54FjqqIVo"
      },
      "outputs": [],
      "source": [
        "go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=line.flatten(),\n",
        "            y=G()(line).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "        )\n",
        "    ]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voRsVHueqIVo"
      },
      "outputs": [],
      "source": [
        "next(iter(dataloader.DataLoader(p_real, batch_size=10, shuffle=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU0QHY2pqIVp"
      },
      "outputs": [],
      "source": [
        "line_space = torch.linspace(-10, 10, 1000).reshape(-1, 1)\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=D()(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"discriminator\",\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=G()(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"generator\",\n",
        "        ),\n",
        "        go.Scatter(x=bin_count, y=bin_centers, mode=\"lines\", name=\"real\"),\n",
        "    ]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYAU-_9XhaN5"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKLKAobDf3fH"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymhHnlSvqIVp"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "num_batch = ceil(len(p_real) / batch_size) * epochs\n",
        "record_data = pd.DataFrame(\n",
        "    {\"epoch\": int(), \"batch\": int(), \"loss_d\": float(), \"loss_g\": float()},\n",
        "    index=range(num_batch),\n",
        ")\n",
        "example_gen = torch.empty(epochs, 100, 1)\n",
        "generator = G().to(device)\n",
        "discriminator = D().to(device)\n",
        "optim_d = optim.Adam(D().parameters())\n",
        "optim_g = optim.Adam(G().parameters())\n",
        "loss_fn = nn.BCELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aRdjGyzqIVp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF6Ak20bqIVp"
      },
      "outputs": [],
      "source": [
        "run_ind = 0\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    data_loader = dataloader.DataLoader(p_real, batch_size=batch_size, shuffle=True)\n",
        "    for batch_ind, points in enumerate(data_loader):\n",
        "        points = points.to(device)\n",
        "        # Train discriminator\n",
        "        optim_d.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 1, device=device))\n",
        "        loss_d = loss_fn(\n",
        "            discriminator(points), torch.ones(len(points), 1, device=device)\n",
        "        )\n",
        "        loss_d += loss_fn(\n",
        "            discriminator(fake), torch.zeros(len(points), 1, device=device)\n",
        "        )\n",
        "        loss_d = loss_d / 2\n",
        "        loss_d.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "        # Train generator\n",
        "        optim_g.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 1, device=device))\n",
        "        loss_g = loss_fn(discriminator(fake), torch.ones(len(points), 1, device=device))\n",
        "        loss_g.backward()\n",
        "        optim_g.step()\n",
        "        # Record losses\n",
        "        record_data.iloc[run_ind] = epoch, batch_ind, loss_d.item(), loss_g.item()\n",
        "        run_ind += 1\n",
        "    # clear_output(wait=True)\n",
        "    # with torch.no_grad():\n",
        "    #     example_gen[epoch] = generator(torch.rand(100, 1, device=device)).detach().cpu()\n",
        "    #     px.line(\n",
        "    #         record_data, x=\"batch\", y=[\"loss_d\", \"loss_g\"], animation_frame=\"epoch\"\n",
        "    #     ).show()\n",
        "    #     px.histogram(example_gen[epoch], marginal=\"rug\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL36EGnPqIVp"
      },
      "outputs": [],
      "source": [
        "line_space = torch.linspace(-10, 10, 1000).reshape(-1, 1)\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=discriminator(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"discriminator\",\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=generator(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"generator\",\n",
        "        ),\n",
        "        go.Scatter(x=bin_count, y=bin_centers, mode=\"lines\", name=\"real\"),\n",
        "    ]\n",
        ").show()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
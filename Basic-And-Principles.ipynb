{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avrymi-asraf/Garden-of-GAN/blob/main/Basic-And-Principles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6B4zf9Ptk36"
      },
      "source": [
        "# Basic and Principle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installations and Import"
      ],
      "metadata": {
        "id": "NpgcMhget3UH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ygl-dhvvfDp"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchvision plotly tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYYopqePvwtD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.utils.data.dataloader as dataloader\n",
        "from torchvision import datasets, transforms\n",
        "import plotly.express as px\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "6ENLba0wvSpv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-q6pCrxIwHJy"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, letant_dim: int, im_dim):\n",
        "        super().__init__()\n",
        "        self.im_dim = im_dim\n",
        "        self.len_im = im_dim[0] * im_dim[1]\n",
        "        self.letant_dim = letant_dim\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(letant_dim, 256),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(256, self.len_im),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.model(X.view((-1, self.letant_dim))).view((-1, *self.im_dim))\n",
        "\n",
        "\n",
        "class Discrimnator(nn.Module):\n",
        "    def __init__(self, im_dim) -> None:\n",
        "        super().__init__()\n",
        "        self.im_dim = im_dim\n",
        "        self.len_im = im_dim[0] * im_dim[1]\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(self.len_im, 128), nn.LeakyReLU(), nn.Linear(128, 1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.model(X.view(-1, self.len_im)).view(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2X5wWW4zRf5"
      },
      "outputs": [],
      "source": [
        "transfomer = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
        "mnist_data = datasets.MNIST(\"/dataset\", download=True, transform=transfomer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRigTOsG9VT0"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9rFVcMlz6N3"
      },
      "outputs": [],
      "source": [
        "letant_dim = 100\n",
        "im_dim = (28, 28)\n",
        "generator = Generator(letant_dim, im_dim).to(device)\n",
        "discrimnator = Discrimnator(im_dim).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4V8TSFKy_py"
      },
      "outputs": [],
      "source": [
        "lr = 3e-4\n",
        "optim_g = optim.Adam(generator.parameters(), lr=lr)\n",
        "optim_d = optim.Adam(discrimnator.parameters(), lr=lr)\n",
        "loss_f = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJUSaZ5h0-f6"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "\n",
        "num_epochs = 32\n",
        "batch_size = 64\n",
        "out_data = pd.DataFrame(\n",
        "    {\"epoch\": pd.NA, \"batch\": pd.NA, \"loss_g\": pd.NA, \"loss_d\": pd.NA},\n",
        "    index=range(num_epochs * ceil(len(mnist_data) / batch_size)),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K66ATVud1kj3"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "ind_out_data = 0\n",
        "for epoch_ind in range(num_epochs):\n",
        "    loader = dataloader.DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
        "    for i_batch, (X, _) in enumerate(loader):\n",
        "        optim_g.zero_grad()\n",
        "        optim_d.zero_grad()\n",
        "        noise = torch.rand(X.shape[0], letant_dim).to(device)\n",
        "        fake = generator(noise)\n",
        "        loss_d_fake = loss_f(discrimnator(fake), torch.zeros(fake.shape[0]).to(device))\n",
        "        loss_d_real = loss_f(\n",
        "            discrimnator(X.to(device)), torch.ones(X.shape[0]).to(device)\n",
        "        )\n",
        "        loss_d = (loss_d_fake + loss_d_real) / 2\n",
        "        loss_d.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "\n",
        "        loss_g = loss_f(discrimnator(fake), torch.ones(fake.shape[0]).to(device))\n",
        "        loss_g.backward()\n",
        "        optim_g.step()\n",
        "        out_data.loc[ind_out_data] = [epoch_ind, i_batch, loss_g.item(), loss_d.item()]\n",
        "        ind_out_data += 1\n",
        "    with torch.no_grad():\n",
        "        noise = torch.rand(10, letant_dim)\n",
        "        im = generator(noise.to(device))\n",
        "        clear_output(wait=True)\n",
        "        px.imshow(im.cpu().detach(), facet_col=0, facet_col_wrap=5).show()\n",
        "        px.line(out_data, x=\"batch\", y=\"loss_g\", color=\"epoch\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-cTCXaS-Dna"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "from IPython.display import clear_output\n",
        "\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "out_data = pd.DataFrame(\n",
        "    {\"epochs\": pd.NA, \"batch\": pd.NA, \"loss_g\": pd.NA, \"loss_d\": pd.NA},\n",
        "    index=range(num_epochs * ceil(len(mnist_data) / batch_size)),\n",
        ")\n",
        "index_data = 0\n",
        "for epoch in range(num_epochs):\n",
        "    loader = dataloader.DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
        "    for batch_i, (X, _) in enumerate(loader):\n",
        "        curr_batch_size = X.shape[0]\n",
        "\n",
        "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
        "        noise = torch.randn(curr_batch_size, letant_dim).to(device)\n",
        "        fake = generator(noise)\n",
        "        disc_real = discrimnator(X.to(device)).view(-1)\n",
        "        lossD_real = loss_f(disc_real, torch.ones_like(disc_real).to(device))\n",
        "        disc_fake = discrimnator(fake).view(-1)\n",
        "        lossD_fake = loss_f(disc_fake, torch.zeros_like(disc_fake).to(device))\n",
        "        lossD = (lossD_real + lossD_fake) / 2\n",
        "        optim_d.zero_grad()\n",
        "        lossD.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "\n",
        "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
        "        # where the second option of maximizing doesn't suffer from\n",
        "        # saturating gradients\n",
        "        output = discrimnator(fake).view(-1)\n",
        "        lossG = loss_f(output, torch.ones_like(output).to(device))\n",
        "        optim_g.zero_grad()\n",
        "        lossG.backward()\n",
        "        optim_g.step()\n",
        "\n",
        "        out_data.loc[index_data] = [epoch, batch_i, lossG.item(), lossD.item()]\n",
        "        index_data += 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "        fake = generator(torch.rand(10, 100).to(device))\n",
        "        clear_output(wait=True)\n",
        "        px.imshow(fake.cpu().detach(), facet_col=0, facet_col_wrap=5).show()\n",
        "        px.line(out_data, x=\"batch\", y=[\"loss_g\"], color=\"epochs\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpnVR8ry66Yi"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchvision plotly black[jupyter] tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y6bger-7ZT3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import dataloader\n",
        "from torchvision import transforms, datasets\n",
        "from plotly import express as px, graph_objects as go\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrukyl_y0b2c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "\n",
        "# drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXlVnKwqm5Ey"
      },
      "outputs": [],
      "source": [
        "# !black '/content/drive/MyDrive/gan_for_Day/chang_train_ratio_6/update_in_run_time_6.ipynb'\n",
        "# !black '/content/drive/MyDrive/Colab Notebooks/gan_for_Day/chang_train_ratio_6/update_in_run_time_6.ipynb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cIClnPN7aqp"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, List\n",
        "\n",
        "ImageDimType = Tuple[int, int]\n",
        "ImageType = torch.Tensor\n",
        "TensorType = torch.Tensor\n",
        "DataSetVisionType = datasets.vision.VisionDataset\n",
        "LossFunctionType = nn.modules.loss._WeightedLoss\n",
        "OptimizerType = optim.Optimizer\n",
        "DeviceType = str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m23ppIqefGDf"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "## יצירת הדטה"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JReS6LtM4XDz"
      },
      "outputs": [],
      "source": [
        "f = lambda x:  x**2 + 10\n",
        "X = (torch.randn(1000)-0.5)*10\n",
        "y = f(X)\n",
        "Xy = torch.stack([X,y]) # 2x1000,on the first row is X, on the second row is y\n",
        "data = Xy.T             # 1000x2, every row is a sample\n",
        "px.scatter(x=Xy[0],y=Xy[1]).show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC4xo82tfs_E"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "## יצירת המודלים\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psVcCbDo4XD0"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(16, 32),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(32, 2),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9WmTri8MO38"
      },
      "outputs": [],
      "source": [
        "px.scatter(*Generator()(torch.randn(10000, 2)).detach().T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBkOV6Sz4XD1"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, 16),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(16, 16),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVhiVCYn4XD1"
      },
      "outputs": [],
      "source": [
        "Discriminator()(torch.randn(10,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_7rbf0B7frl"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "discriminator = Discriminator().to(device)\n",
        "generator = Generator().to(device)\n",
        "optim_d = optim.Adam(Discriminator().parameters())\n",
        "optim_g = optim.Adam(Generator().parameters())\n",
        "loss_fn = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFt9WRIOf1GV"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "## אימון"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPUV6AAG4XD2"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "epochs = 300\n",
        "batch_size = 64\n",
        "num_batch = ceil(len(data)/batch_size)\n",
        "record_data = pd.DataFrame(\n",
        "    {\"epoch\": int(), \"batch\": int(), \"loss_d\": float(), \"loss_g\": float()},\n",
        "    index=range(epochs * num_batch),\n",
        ")\n",
        "example_gen = torch.empty(epochs,10,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65WsO9Ed4XD2"
      },
      "outputs": [],
      "source": [
        "run_ind = 0\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    data_loader = dataloader.DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "    for batch_ind, points in enumerate(data_loader):\n",
        "        points = points.to(device)\n",
        "        # Train discriminator\n",
        "        optim_d.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 2, device=device))\n",
        "        loss_d = loss_fn(\n",
        "            discriminator(points), torch.ones(len(points),1, device=device)\n",
        "        )\n",
        "        loss_d += loss_fn(\n",
        "            discriminator(fake), torch.zeros(len(points),1, device=device)\n",
        "        )\n",
        "        loss_d.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "        # Train generator\n",
        "        optim_g.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 2, device=device))\n",
        "        loss_g = loss_fn(discriminator(fake), torch.ones(len(points),1, device=device))\n",
        "        loss_g.backward()\n",
        "        optim_g.step()\n",
        "        # Record losses\n",
        "        record_data.iloc[run_ind] = epoch, batch_ind, loss_d.item(), loss_g.item()\n",
        "        run_ind += 1\n",
        "    clear_output(wait=True)\n",
        "    with torch.no_grad():\n",
        "        example_gen[epoch] = generator(torch.rand(10,2,device=device)).detach().cpu()\n",
        "px.line(\n",
        "    record_data, x=\"batch\", y=[\"loss_d\", \"loss_g\"], animation_frame=\"epoch\"\n",
        ").show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP2bWlWr__Kx"
      },
      "outputs": [],
      "source": [
        "example_gen = example_gen.transpose(2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITeZLVTn_rM2"
      },
      "outputs": [],
      "source": [
        "# @title { run: \"auto\" }\n",
        "ind = 279 # @param {type:\"slider\", min:0, max:299, step:1}\n",
        "px.scatter(x=example_gen[ind,0],y=example_gen[ind,1]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Pr8-ZlB7Xj"
      },
      "outputs": [],
      "source": [
        "px.scatter(example_gen)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw8vIbohqIVo"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "var, mean = random.randint(0, 10), random.randint(0, 10)\n",
        "p_real = (torch.randn(10000) * var + mean).reshape(-1, 1)\n",
        "bin_centers, bin_count = torch.histogram(p_real, bins=30, density=True)\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=bin_count,\n",
        "            y=bin_centers,\n",
        "            mode=\"lines\",\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7n8F3AbZqIVo"
      },
      "outputs": [],
      "source": [
        "class D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(1, 2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(2, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "class G(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(1, 1),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "line = torch.linspace(-10,10,10).reshape(-1,1)\n",
        "print(G()(line))\n",
        "print(D()(line))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c-54FjqqIVo"
      },
      "outputs": [],
      "source": [
        "go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=line.flatten(),\n",
        "            y=G()(line).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "        )\n",
        "    ]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voRsVHueqIVo"
      },
      "outputs": [],
      "source": [
        "next(iter(dataloader.DataLoader(p_real, batch_size=10, shuffle=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU0QHY2pqIVp"
      },
      "outputs": [],
      "source": [
        "line_space = torch.linspace(-10, 10, 1000).reshape(-1, 1)\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=D()(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"discriminator\",\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=G()(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"generator\",\n",
        "        ),\n",
        "        go.Scatter(x=bin_count, y=bin_centers, mode=\"lines\", name=\"real\"),\n",
        "    ]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYAU-_9XhaN5"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "## פונקצייות"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKLKAobDf3fH"
      },
      "source": [
        "<div dir=\"rtl\" lang=\"he\" xml:lang=\"he\">\n",
        "\n",
        "##הרצה"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymhHnlSvqIVp"
      },
      "outputs": [],
      "source": [
        "from math import ceil\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "num_batch = ceil(len(p_real) / batch_size) * epochs\n",
        "record_data = pd.DataFrame(\n",
        "    {\"epoch\": int(), \"batch\": int(), \"loss_d\": float(), \"loss_g\": float()},\n",
        "    index=range(num_batch),\n",
        ")\n",
        "example_gen = torch.empty(epochs, 100, 1)\n",
        "generator = G().to(device)\n",
        "discriminator = D().to(device)\n",
        "optim_d = optim.Adam(D().parameters())\n",
        "optim_g = optim.Adam(G().parameters())\n",
        "loss_fn = nn.BCELoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aRdjGyzqIVp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GF6Ak20bqIVp"
      },
      "outputs": [],
      "source": [
        "run_ind = 0\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    data_loader = dataloader.DataLoader(p_real, batch_size=batch_size, shuffle=True)\n",
        "    for batch_ind, points in enumerate(data_loader):\n",
        "        points = points.to(device)\n",
        "        # Train discriminator\n",
        "        optim_d.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 1, device=device))\n",
        "        loss_d = loss_fn(\n",
        "            discriminator(points), torch.ones(len(points), 1, device=device)\n",
        "        )\n",
        "        loss_d += loss_fn(\n",
        "            discriminator(fake), torch.zeros(len(points), 1, device=device)\n",
        "        )\n",
        "        loss_d = loss_d / 2\n",
        "        loss_d.backward(retain_graph=True)\n",
        "        optim_d.step()\n",
        "        # Train generator\n",
        "        optim_g.zero_grad()\n",
        "        fake = generator(torch.randn(len(points), 1, device=device))\n",
        "        loss_g = loss_fn(discriminator(fake), torch.ones(len(points), 1, device=device))\n",
        "        loss_g.backward()\n",
        "        optim_g.step()\n",
        "        # Record losses\n",
        "        record_data.iloc[run_ind] = epoch, batch_ind, loss_d.item(), loss_g.item()\n",
        "        run_ind += 1\n",
        "    # clear_output(wait=True)\n",
        "    # with torch.no_grad():\n",
        "    #     example_gen[epoch] = generator(torch.rand(100, 1, device=device)).detach().cpu()\n",
        "    #     px.line(\n",
        "    #         record_data, x=\"batch\", y=[\"loss_d\", \"loss_g\"], animation_frame=\"epoch\"\n",
        "    #     ).show()\n",
        "    #     px.histogram(example_gen[epoch], marginal=\"rug\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL36EGnPqIVp"
      },
      "outputs": [],
      "source": [
        "line_space = torch.linspace(-10, 10, 1000).reshape(-1, 1)\n",
        "fig = go.Figure(\n",
        "    data=[\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=discriminator(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"discriminator\",\n",
        "        ),\n",
        "        go.Scatter(\n",
        "            x=line_space.flatten(),\n",
        "            y=generator(line_space).detach().flatten(),\n",
        "            mode=\"lines\",\n",
        "            name=\"generator\",\n",
        "        ),\n",
        "        go.Scatter(x=bin_count, y=bin_centers, mode=\"lines\", name=\"real\"),\n",
        "    ]\n",
        ").show()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}